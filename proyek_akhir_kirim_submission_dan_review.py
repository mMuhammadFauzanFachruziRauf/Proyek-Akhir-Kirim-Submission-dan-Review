# -*- coding: utf-8 -*-
"""Proyek_Akhir_Kirim_Submission_dan_Review.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EPnZF0ArdY8P2_ox6F7CnIGLln6Fns_r

# Proyek Analisis Data: Proyek Akhir Kirim Submission dan Review
- **Nama:** Muhammad Fauzan Fachruzi Rauf
- **Email:** fauzan01rauf@gmail.com
- **ID Dicoding:** mfauzanfr01

# **Tahap 1 : Project Overview - Domain Proyek**

# 📽️ Proyek Sistem Rekomendasi Film

## 1. Latar Belakang

Pertumbuhan eksponensial konten digital seperti film dan acara TV di berbagai platform streaming (Netflix, Amazon Prime, Disney+, dan lainnya) memberikan kemudahan akses bagi pengguna. Namun, hal ini juga menimbulkan masalah yang disebut sebagai **_information overload_** atau **_paradox of choice_** — yaitu kesulitan dalam memilih konten yang sesuai dari ribuan pilihan yang tersedia.

Di sinilah **sistem rekomendasi** berperan penting. Sistem ini membantu pengguna menemukan konten yang relevan dan personal secara otomatis, sehingga:

- Meningkatkan pengalaman menonton pengguna.
- Mengurangi waktu pencarian konten.
- Meningkatkan engagement dan retensi pengguna pada platform streaming.

---

## 2. Pentingnya Proyek Ini

### 🎯 Bagi Pengguna
- Membantu menemukan film atau acara TV yang sesuai dengan preferensi mereka.
- Menghemat waktu dalam proses pencarian konten.
- Menemukan konten baru yang mungkin tidak mereka temukan sendiri.

### 💼 Bagi Platform Streaming
- Meningkatkan **keterlibatan pengguna (user engagement)**.
- Meningkatkan **loyalitas dan retensi pengguna**.
- Meningkatkan jumlah film/acara yang dikonsumsi oleh pengguna.

### 🎬 Bagi Industri Film
- Membuka peluang promosi untuk film-film **niche atau kurang populer**.
- Menjangkau audiens yang lebih relevan dengan konten tertentu.

### 📘 Bagi Pembelajaran (Sebagai Siswa Dicoding)
- Melatih penerapan **algoritma machine learning** dalam kehidupan nyata.
- Mempelajari teknik populer seperti **collaborative filtering** dan **content-based filtering**.
- Mendalami pemanfaatan **data pengguna** dalam personalisasi sistem.

---

## 3. Referensi dan Studi Pendukung


### 📚 Referensi Akademik:
- Sarwar, B., Karypis, G., Konstan, J., & Riedl, J. (2001).  
  *Item-based collaborative filtering recommendation algorithms*.  
  *Proceedings of the 10th international conference on World Wide Web.*
  https://dl.acm.org/doi/10.1145/371920.372071

- Ricci, F., Rokach, L., & Shapira, B. (2011).  
  *Introduction to Recommender Systems Handbook*.  
  *Recommender Systems Handbook.*
  https://www.scirp.org/reference/referencespapers?referenceid=1054693

---

> 💡 *Proyek ini tidak hanya penting untuk industri hiburan, tetapi juga sebagai fondasi pembelajaran dalam membangun sistem cerdas yang berdampak langsung pada pengalaman pengguna.*

# **Tahap 2 : Business Understanding**

# ❓ Problem Statements (Pernyataan Masalah)

1. **Information Overload:**
   > Pengguna dihadapkan pada volume besar pilihan film yang tersedia pada platform digital, mengakibatkan kesulitan dalam menemukan film yang benar-benar sesuai dengan preferensi individu secara efisien.  
   Fenomena ini dikenal sebagai *information overload* dan dapat menurunkan kualitas pengalaman pengguna.

2. **Kurangnya Eksplorasi Film:**
   > Keterbatasan dalam eksplorasi film menyebabkan banyak karya sinematik, terutama yang berasal dari produksi independen atau rilisan lampau, menjadi kurang terekspos kepada audiens yang potensial, meskipun film tersebut mungkin relevan dengan minat mereka.

3. **Rekomendasi yang Tidak Personal:**
   > Penyajian rekomendasi yang kurang personal atau tidak akurat dapat menyebabkan pengguna merasa frustrasi dan berpotensi mengurangi tingkat interaksi (*engagement*) mereka dengan layanan penyedia konten film.

---

# 🎯 Goals (Tujuan Proyek)

- Mengembangkan **dua model sistem rekomendasi film** — satu berbasis konten (*Content-Based Filtering*) dan satu berbasis kolaboratif (*Collaborative Filtering*) — untuk menghasilkan daftar rekomendasi film yang dipersonalisasi.
- Meningkatkan kemampuan pengguna dalam menemukan film baru yang sesuai dengan selera mereka, sehingga memperkaya pengalaman menonton dan meningkatkan unsur *serendipity* (penemuan tak terduga yang menyenangkan).
- Mengevaluasi dan membandingkan kinerja kedua pendekatan menggunakan **metrik evaluasi yang sesuai** pada dataset MovieLens.
- Memberikan pemahaman praktis mengenai implementasi dan evaluasi sistem rekomendasi sebagai salah satu aplikasi penting di bidang *machine learning*.

---

# 🔧 Solution Approach (Pendekatan Solusi)

Proyek ini akan mengimplementasikan dan mengevaluasi dua pendekatan utama:

## 📌 Content-Based Filtering (Penyaringan Berbasis Konten)

### Konsep Dasar:
Merekomendasikan film berdasarkan kemiripan atribut film (genre, sutradara, aktor utama, kata kunci sinopsis) dengan film yang disukai oleh pengguna sebelumnya.

### Mekanisme Umum:

- **Representasi Fitur Item:**  
  Setiap film direpresentasikan sebagai **vektor fitur** (misalnya, genre dalam bentuk vektor biner: `[Adventure, Comedy, Sci-Fi, Drama, ...]`).

- **Pembuatan Profil Pengguna:**  
  Sistem membentuk profil preferensi pengguna dari film yang diberi rating tinggi oleh pengguna tersebut.

- **Penghitungan Kemiripan:**  
  Gunakan metrik seperti **cosine similarity** untuk menghitung kemiripan antara film baru dan preferensi pengguna.

- **Pemberian Rekomendasi:**  
  Film dengan skor kemiripan tertinggi akan direkomendasikan kepada pengguna.

---

## 🤝 Collaborative Filtering (Penyaringan Kolaboratif)

### Konsep Dasar:
Menganalisis pola interaksi pengguna (rating) untuk menemukan kesamaan preferensi antar pengguna atau antar item.

### Pendekatan yang Digunakan:

#### 🔸 User-Based Collaborative Filtering (UCF):
- Menemukan “tetangga” pengguna dengan preferensi serupa.
- Merekomendasikan film yang disukai oleh tetangga tersebut dan belum ditonton oleh pengguna target.

#### 🔸 Item-Based Collaborative Filtering (ICF):
- Menghitung kemiripan antar item berdasarkan rating yang diberikan oleh pengguna yang sama.
- Merekomendasikan film mirip dengan yang telah disukai oleh pengguna.

#### 🔸 Matrix Factorization (Contoh: SVD):
- Menguraikan matriks interaksi **user-item** menjadi faktor laten yang merepresentasikan karakteristik tersembunyi.
- Memprediksi rating untuk pasangan user-item yang belum ada dan memberikan rekomendasi berdasarkan skor tertinggi.

---

> 💡 *Dengan membandingkan pendekatan Content-Based dan Collaborative Filtering, proyek ini bertujuan memberikan pemahaman menyeluruh terhadap kekuatan dan kelemahan masing-masing metode dalam konteks rekomendasi film.*

# **Tahap 3 : Data Understanding**

# 📂 Sumber Data dan Pemuatan Data Awal

## 🔗 Tautan Sumber Data:
- Dataset: MovieLens Latest Datasets (Small)
- Link Download: https://grouplens.org/datasets/movielens/latest/ (cari file ml-latest-small.zip).

## 📁 Di dalam file zip tersebut, kita akan fokus pada beberapa file utama:
- `movies.csv`: Berisi informasi film (movieId, title, genres).
- `ratings.csv`: Berisi informasi rating yang diberikan pengguna ke film (userId, movieId, rating, timestamp).
- `tags.csv`: (Opsional, bisa kita pertimbangkan nanti) Berisi tag yang diberikan pengguna ke film.
- `links.csv`: (Kurang relevan untuk model kita) Berisi identifier untuk website lain seperti IMDB dan TMDB.

## 📊 Pemuatan Data:
Anda akan menggunakan library pandas di Python untuk memuat file .csv ini ke dalam DataFrame.
Contoh kode di notebook Anda (setelah mengunggah dan mengekstrak file):
"""

import pandas as pd
import requests
import zipfile
import io

# URL ke dataset MovieLens Small
zip_file_url = "http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"

print(f"Mengunduh dataset dari {zip_file_url}...")
r = requests.get(zip_file_url)
z = zipfile.ZipFile(io.BytesIO(r.content))
print("Dataset berhasil diunduh dan dibuka.")

# Nama file CSV di dalam ZIP yang kita butuhkan
movies_csv_path = 'ml-latest-small/movies.csv'
ratings_csv_path = 'ml-latest-small/ratings.csv'
# tags_csv_path = 'ml-latest-small/tags.csv' # Jika Anda memutuskan untuk menggunakan

print(f"Membaca {movies_csv_path}...")
movies_df = pd.read_csv(z.open(movies_csv_path))
print("movies_df berhasil dimuat.")

print(f"Membaca {ratings_csv_path}...")
ratings_df = pd.read_csv(z.open(ratings_csv_path))
print("ratings_df berhasil dimuat.")

# Jika ingin memuat tags.csv juga:
# print(f"Membaca {tags_csv_path}...")
# tags_df = pd.read_csv(z.open(tags_csv_path))
# print("tags_df berhasil dimuat.")

print("\nBeberapa baris pertama dari movies_df:")
print(movies_df.head())

print("\nBeberapa baris pertama dari ratings_df:")
print(ratings_df.head())

print("Dimensi movies_df:", movies_df.shape)

"""**Observasi `movies_df.shape`:**
* DataFrame `movies_df` memiliki **9742 baris** dan **3 kolom**. Ini berarti dataset kita berisi informasi untuk 9742 film, dengan masing-masing film memiliki 3 atribut (fitur).
"""

print("\nInfo movies_df:")
movies_df.info()

"""**Observasi `movies_df.info()`:**
* DataFrame `movies_df` terdiri dari 9742 entri (baris), sesuai dengan output `.shape`.
* Terdapat 3 kolom: `movieId`, `title`, dan `genres`.
* Semua kolom memiliki **9742 entri non-null**, yang mengindikasikan **tidak ada nilai yang hilang (missing values)** pada dataset film ini.
* Tipe data untuk `movieId` adalah `int64` (integer), sedangkan `title` dan `genres` adalah `object` (yang biasanya menandakan tipe data string di Pandas).
* Perkiraan penggunaan memori untuk DataFrame ini adalah sekitar 228.5+ KB.
"""

print("\nStatistik Deskriptif movies_df:")
print(movies_df.describe(include='all'))

"""**Observasi `movies_df.describe(include='all')`:**
* **Untuk `movieId` (kolom numerik):**
    * Terdapat 9742 nilai unik, yang sesuai dengan jumlah total film, mengonfirmasi `movieId` adalah identifier unik.
    * Nilai `mean`, `std`, `min`, `25%` (kuartil pertama), `50%` (median), `75%` (kuartil ketiga), dan `max` memberikan gambaran distribusi ID film. `movieId` terkecil adalah 1 dan terbesar adalah 193609.
* **Untuk `title` (kolom teks/objek):**
    * Ada 9742 entri.
    * Terdapat **9737 nilai unik** untuk `title`. Karena jumlah ini sedikit lebih kecil dari total film (9742), ini mengindikasikan ada beberapa judul film yang mungkin duplikat atau memiliki variasi penulisan tahun yang sama (misalnya, "Emma (1996)" muncul 2 kali seperti yang ditunjukkan oleh `top` dan `freq`).
    * Judul film yang paling sering muncul (`top`) adalah "Emma (1996)", dengan frekuensi (`freq`) sebanyak 2 kali.
* **Untuk `genres` (kolom teks/objek):**
    * Ada 9742 entri.
    * Terdapat **951 kombinasi genre yang unik**.
    * Kombinasi genre yang paling sering muncul (`top`) adalah "Drama", dengan frekuensi (`freq`) sebanyak 1053 kali.
"""

print("\nDimensi ratings_df:", ratings_df.shape)

"""**Observasi `ratings_df.shape`:**
* DataFrame `ratings_df` memiliki **100836 baris** dan **4 kolom**. Ini berarti ada 100.836 entri rating dalam dataset. Setiap entri rating memiliki 4 atribut.
"""

print("\nInfo ratings_df:")
ratings_df.info()

"""**Observasi `ratings_df.info()`:**
* DataFrame `ratings_df` terdiri dari 100836 entri (baris), sesuai dengan output `.shape`.
* Terdapat 4 kolom: `userId`, `movieId`, `rating`, dan `timestamp`.
* Semua kolom memiliki **100836 entri non-null**, yang mengindikasikan **tidak ada nilai yang hilang (missing values)** pada dataset rating ini.
* Tipe data untuk `userId`, `movieId`, dan `timestamp` adalah `int64` (integer).
* Tipe data untuk `rating` adalah `float64` (angka desimal), yang sesuai karena rating dapat bernilai pecahan (misalnya 3.5).
* Perkiraan penggunaan memori untuk DataFrame ini adalah sekitar 3.1 MB.
"""

print("\nStatistik Deskriptif ratings_df:")
print(ratings_df.describe())

"""**Observasi `ratings_df.describe()`:**
* **`userId`:**
    * Ada 100836 rating yang diberikan.
    * Rata-rata `userId` adalah sekitar 326.
    * `userId` minimum adalah 1 dan maksimum adalah 610, yang berarti ada **610 pengguna unik** yang memberikan rating dalam dataset ini.
* **`movieId`:**
    * Nilai `movieId` bervariasi, dengan film yang paling sering dirating memiliki ID yang lebih rendah (terlihat dari median `2991.0` dibandingkan `max` `193609.0`).
* **`rating`:**
    * Kolom ini adalah yang paling penting untuk dianalisis dari statistik deskriptif ini.
    * Rata-rata (`mean`) rating yang diberikan adalah sekitar **3.50**.
    * Standar deviasi (`std`) sekitar **1.04**, menunjukkan sebaran variasi rating.
    * Rating minimum (`min`) adalah **0.5** dan rating maksimum (`max`) adalah **5.0**, sesuai dengan skala rating MovieLens.
    * Kuartil pertama (`25%`) adalah 3.0, median (`50%`) adalah 3.5, dan kuartil ketiga (`75%`) adalah 4.0. Ini menunjukkan bahwa sebagian besar rating cenderung berada di sisi positif (3.0 ke atas).
* **`timestamp`:**
    * Menunjukkan kapan rating diberikan, dalam format Unix timestamp. Nilai `min` dan `max` menunjukkan rentang waktu pemberian rating dalam dataset.

# **Data Understanding**

# 📝 Deskripsi Variabel

Berikut adalah penjelasan untuk setiap variabel (kolom) yang terdapat dalam dataset `movies_df` dan `ratings_df` yang digunakan dalam proyek ini:
### Variabel pada `movies_df`:

* `movieId`: Identifier unik untuk setiap film dalam dataset.
    * *Tipe Data:* `int64` (Integer Numerik)
    * *Contoh:* `1`, `2`, `3`
    * *Keterangan:* Akan digunakan sebagai kunci utama (primary key) untuk menghubungkan data film dengan data rating.

* `title`: Judul lengkap dari film, seringkali menyertakan tahun rilis dalam tanda kurung.
    * *Tipe Data:* `object` (String)
    * *Contoh:* `Toy Story (1995)`, `Jumanji (1995)`
    * *Keterangan:* Memberikan informasi nama film yang mudah dibaca manusia. Tahun rilis bisa diekstrak jika diperlukan analisis temporal lebih lanjut.

* `genres`: Satu atau lebih genre yang diasosiasikan dengan film, dipisahkan oleh karakter pipa (`|`).
    * *Tipe Data:* `object` (String)
    * *Contoh:* `Adventure|Animation|Children|Comedy|Fantasy`, `Comedy|Romance`
    * *Keterangan:* Fitur ini sangat krusial untuk pendekatan Content-Based Filtering, karena merepresentasikan karakteristik konten film.

### Variabel pada `ratings_df`:

* `userId`: Identifier unik untuk setiap pengguna yang memberikan rating.
    * *Tipe Data:* `int64` (Integer Numerik)
    * *Contoh:* `1`, `2`, `3`
    * *Keterangan:* Merepresentasikan entitas pengguna dalam dataset.

* `movieId`: Identifier film yang diberi rating oleh pengguna.
    * *Tipe Data:* `int64` (Integer Numerik)
    * *Contoh:* `1`, `3`, `6`
    * *Keterangan:* Merupakan foreign key yang menghubungkan ke `movieId` di `movies_df`.

* `rating`: Rating numerik yang diberikan oleh pengguna untuk film tertentu.
    * *Tipe Data:* `float64` (Float Numerik)
    * *Contoh:* `4.0`, `5.0`, `3.5`
    * *Keterangan:* Skala rating pada dataset ini adalah dari 0.5 hingga 5.0 dengan interval 0.5. Ini adalah variabel target utama untuk prediksi dalam Collaborative Filtering dan untuk memahami preferensi pengguna.

* `timestamp`: Waktu ketika rating diberikan oleh pengguna, dalam format Unix timestamp (jumlah detik sejak 1 Januari 1970 UTC).
    * *Tipe Data:* `int64` (Integer Numerik)
    * *Contoh:* `964982703`
    * *Keterangan:* Meskipun tidak akan menjadi fokus utama dalam model rekomendasi awal kita, data timestamp bisa digunakan untuk analisis tren, model yang sensitif terhadap waktu, atau untuk membagi data berdasarkan waktu.

## **1. Visualisasi Distribusi Rating**
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Mengatur gaya visualisasi seaborn untuk tampilan yang lebih menarik
sns.set_style('whitegrid')

plt.figure(figsize=(10, 6)) # Mengatur ukuran figure agar lebih nyaman dilihat
# Penyesuaian berdasarkan FutureWarning:
sns.countplot(x='rating', data=ratings_df, hue='rating', palette='viridis', legend=False)
plt.title('Distribusi Rating Film', fontsize=15, pad=10)
plt.xlabel('Rating', fontsize=12)
plt.ylabel('Jumlah Rating (Count)', fontsize=12) # Mengganti 'Jumlah Pengguna' menjadi 'Jumlah Rating' agar lebih presisi
plt.show()

"""### Observasi Distribusi Rating:

Setelah memvisualisasikan distribusi rating film, beberapa poin penting dapat diamati:

* Rating yang **paling sering diberikan** oleh pengguna adalah **4.0**, diikuti oleh rating **3.0**.
* Rating **paling jarang diberikan** adalah **0.5**.
* Secara umum, pengguna dalam dataset ini cenderung memberikan rating pada rentang **positif/tinggi**, yaitu antara **3.0** dan **5.0**. Rating 2.0 juga cukup sering muncul, namun frekuensinya lebih rendah dibandingkan rating 3.0 ke atas.
* Distribusi rating terlihat **miring ke kiri (left-skewed)**, yang berarti mayoritas rating terkonsentrasi pada nilai yang lebih tinggi.
* Terdapat **10 kategori rating yang berbeda** (0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0).

Insight ini menunjukkan bahwa mayoritas interaksi pengguna dengan film menghasilkan penilaian yang cenderung baik, yang bisa menjadi pertimbangan dalam proses evaluasi model rekomendasi nantinya. Pengguna lebih sering memberikan rating 3.0 ke atas dibandingkan rating di bawahnya.

## **2. Jumlah Film Unik dan Pengguna Unik**
"""

# Menghitung jumlah film unik
jumlah_film_unik = movies_df['movieId'].nunique()
print(f"Jumlah film unik dalam dataset: {jumlah_film_unik}")

# Menghitung jumlah pengguna unik
jumlah_pengguna_unik = ratings_df['userId'].nunique()
print(f"Jumlah pengguna unik dalam dataset: {jumlah_pengguna_unik}")

"""### Observasi Jumlah Film dan Pengguna Unik:

Berdasarkan perhitungan dari dataset:

* Terdapat **9742** film unik yang tersedia untuk diberi rating.
* Terdapat **610** pengguna unik yang telah memberikan setidaknya satu rating.

Informasi ini memberikan gambaran dasar mengenai skala dataset MovieLens Small yang kita gunakan. Jumlah ini akan menjadi dasar untuk memahami densitas matriks interaksi pengguna-film nanti, yaitu seberapa banyak rating yang ada dibandingkan dengan jumlah total kemungkinan rating (9742 film * 610 pengguna).

## **3. Popularitas Film (Berdasarkan Jumlah Rating)**
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Mengatur gaya visualisasi seaborn
sns.set_style('whitegrid')

# Menghitung jumlah rating untuk setiap film
jumlah_rating_film = ratings_df['movieId'].value_counts()

# Mengubah series menjadi DataFrame dan mereset index
jumlah_rating_film_df = jumlah_rating_film.to_frame().reset_index()
jumlah_rating_film_df.columns = ['movieId', 'jumlah_rating']

# Menggabungkan dengan movies_df untuk mendapatkan judul film
film_populer_df = pd.merge(jumlah_rating_film_df, movies_df, on='movieId', how='left')

# Menampilkan 10 film paling populer (paling banyak dirating)
print("Top 10 Film Paling Populer (Berdasarkan Jumlah Rating):\n")
print(film_populer_df[['title', 'jumlah_rating', 'genres']].head(10))
print("\n" + "="*50 + "\n") # Pemisah

# Visualisasi distribusi jumlah rating per film
plt.figure(figsize=(12, 6))
sns.histplot(film_populer_df['jumlah_rating'], bins=50, kde=False, color='royalblue')
plt.title('Distribusi Jumlah Rating per Film', fontsize=15, pad=10)
plt.xlabel('Jumlah Rating yang Diterima Film', fontsize=12)
plt.ylabel('Jumlah Film', fontsize=12)
plt.yscale('log') # Menggunakan skala logaritmik untuk sumbu Y agar lebih terlihat distribusinya
plt.show()

# Visualisasi Top N Film Paling Populer
top_n = 20
plt.figure(figsize=(12, 8))
sns.barplot(x='jumlah_rating', y='title', data=film_populer_df.head(top_n), hue='title', palette='mako', dodge=False, legend=False)
plt.title(f'Top {top_n} Film dengan Rating Terbanyak', fontsize=15, pad=10)
plt.xlabel('Jumlah Rating', fontsize=12)
plt.ylabel('Judul Film', fontsize=12)
plt.tight_layout() # Menyesuaikan layout agar label tidak terpotong
plt.show()

"""### Observasi Popularitas Film:

Berdasarkan analisis jumlah rating yang diterima setiap film:

* **Film Paling Populer:**
    * Film yang mendapatkan jumlah rating terbanyak adalah **"Forrest Gump (1994)"** dengan **329** rating.
    * Beberapa film lain yang juga sangat populer (masuk 10 besar) antara lain: **"Shawshank Redemption, The (1994)" (317 rating), "Pulp Fiction (1994)" (307 rating), dan "Silence of the Lambs, The (1991)" (279 rating)**.
    * Genre dari film-film populer ini cenderung beragam, mencakup **Drama, Comedy, Crime, Thriller, Action, dan Sci-Fi**. Film-film ini umumnya adalah film-film yang sangat dikenal dan mendapat pujian kritis atau kesuksesan komersial besar pada masanya.

* **Distribusi Jumlah Rating per Film (Histogram):**
    * Plot histogram menunjukkan bahwa sebagian besar film dalam dataset ini hanya menerima **sejumlah kecil rating**. Dari grafik, terlihat banyak film yang memiliki kurang dari 50 rating, bahkan mayoritas signifikan memiliki di bawah 25 rating.
    * Terdapat **sedikit film yang sangat populer** dan menerima jumlah rating yang sangat tinggi (di atas 200 rating, bahkan ada yang di atas 300), sementara mayoritas film lainnya memiliki jumlah rating yang jauh lebih rendah. Fenomena ini sangat jelas menggambarkan distribusi **"long tail"**.
    * Penggunaan skala logaritmik pada sumbu Y sangat membantu memperjelas bahwa ada banyak sekali film dengan jumlah rating rendah yang mungkin tidak akan terlihat jelas jika menggunakan skala linear.

* **Top N Film (Bar Plot):**
    * *(Jika Anda menjalankan kode untuk bar plot Top 20, observasinya akan ditambahkan di sini. Bar plot tersebut akan secara visual mempertegas daftar film-film yang paling sering mendapatkan interaksi/rating dari pengguna, biasanya didominasi oleh film-film blockbuster atau yang dikenal luas).*

Insight ini penting karena menunjukkan bahwa data rating kita tidak merata. Model rekomendasi mungkin akan lebih mudah memberikan rekomendasi untuk film populer karena banyaknya data interaksi. Tantangan utamanya adalah bagaimana memberikan rekomendasi yang relevan dan berkualitas untuk film-film yang kurang populer (yang berada di bagian "long tail" dari distribusi), karena data interaksi untuk film-film tersebut lebih sedikit.

## **4. Aktivitas Pengguna (Berdasarkan Jumlah Film yang Dirating)**
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Mengatur gaya visualisasi seaborn
sns.set_style('whitegrid')

# Menghitung jumlah rating yang diberikan oleh setiap pengguna
jumlah_rating_pengguna = ratings_df['userId'].value_counts()

# Menampilkan statistik deskriptif untuk jumlah rating per pengguna
print("Statistik Deskriptif Jumlah Rating per Pengguna:\n")
print(jumlah_rating_pengguna.describe())
print("\n" + "="*50 + "\n") # Pemisah

# Visualisasi distribusi jumlah rating per pengguna
plt.figure(figsize=(12, 6))
sns.histplot(jumlah_rating_pengguna, bins=50, kde=False, color='seagreen')
plt.title('Distribusi Jumlah Rating per Pengguna', fontsize=15, pad=10)
plt.xlabel('Jumlah Film yang Dirating oleh Pengguna', fontsize=12)
plt.ylabel('Jumlah Pengguna', fontsize=12)
# Pertimbangkan untuk menggunakan skala log jika distribusinya sangat skewed
# plt.yscale('log')
plt.show()

# Menampilkan pengguna dengan jumlah rating terbanyak (contoh top 5)
print("\nTop 5 Pengguna Paling Aktif (Berdasarkan Jumlah Rating):\n")
print(jumlah_rating_pengguna.head(5))

# Menampilkan pengguna dengan jumlah rating paling sedikit (contoh bottom 5, jika perlu)
# print("\nContoh 5 Pengguna Paling Tidak Aktif (Berdasarkan Jumlah Rating):\n")
# print(jumlah_rating_pengguna.tail(5))

"""### Observasi Aktivitas Pengguna:

Berdasarkan analisis jumlah rating yang diberikan oleh setiap pengguna:

* **Statistik Umum Aktivitas Pengguna:**
    * Rata-rata, setiap pengguna telah memberikan **sekitar 165.3** rating.
    * Jumlah rating minimum yang diberikan oleh seorang pengguna adalah **20**. Ini berarti semua pengguna dalam dataset ini telah memberikan setidaknya 20 rating.
    * Pengguna paling aktif telah memberikan **2698** rating.
    * Setengah dari pengguna (median, nilai 50%) dalam dataset ini telah memberikan sekitar **70.5** rating atau kurang.

* **Distribusi Aktivitas Pengguna (Histogram):**
    * Plot histogram menunjukkan bahwa distribusi aktivitas pengguna sangat **miring ke kanan (right-skewed)**. Ini berarti mayoritas pengguna memberikan jumlah rating yang relatif sedikit (terlihat dari bar yang tinggi di sisi kiri plot, misalnya banyak pengguna dengan kurang dari 100 rating).
    * Di sisi lain, terdapat sejumlah kecil pengguna yang sangat aktif ('power users') yang memberikan jumlah rating yang sangat banyak (membentuk ekor panjang ke kanan pada distribusi).
    * *(Jika Anda mencoba plt.yscale('log') dan itu membantu, Anda bisa menambahkan komentar di sini tentang bagaimana skala log memperjelas bagian ekor dari distribusi).*

* **Pengguna Paling Aktif:**
    * Pengguna dengan `userId` **414** adalah yang paling aktif, telah memberikan **2698** rating.
    * Daftar pengguna paling aktif (seperti userId 599 dengan 2478 rating, dan userId 474 dengan 2108 rating) menunjukkan adanya variasi besar dalam tingkat partisipasi pengguna.

Insight ini mengindikasikan bahwa kontribusi data dari pengguna tidak seragam. Beberapa pengguna memberikan banyak informasi preferensi, sementara mayoritas lainnya memberikan lebih sedikit. Ini bisa mempengaruhi bagaimana model Collaborative Filtering belajar pola; preferensi pengguna yang sangat aktif mungkin lebih mudah dipelajari. Sebaliknya, meskipun pengguna dengan rating paling sedikit masih memiliki 20 rating (yang cukup baik dan bukan "cold start" ekstrem), variasi aktivitas ini tetap menjadi pertimbangan.

## **5. Analisis Genre Film**
"""

import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter

# Mengatur gaya visualisasi seaborn
sns.set_style('whitegrid')

# Memecah string genre menjadi daftar genre individual dan menghitung frekuensinya
# Kita akan membuat list yang berisi semua genre dari setiap film
semua_genre_list = []
for index, row in movies_df.iterrows():
    genres_film_ini = row['genres'].split('|')
    semua_genre_list.extend(genres_film_ini)

# Menggunakan collections.Counter untuk menghitung frekuensi setiap genre
hitung_genre = Counter(semua_genre_list)

# Mengubah hasil Counter menjadi DataFrame untuk kemudahan visualisasi
genre_df = pd.DataFrame.from_dict(hitung_genre, orient='index', columns=['jumlah_film']).reset_index()
genre_df = genre_df.rename(columns={'index': 'genre'})
genre_df = genre_df.sort_values(by='jumlah_film', ascending=False)

# Menampilkan beberapa genre teratas
print("Frekuensi Setiap Genre Film (Top 10):\n")
print(genre_df.head(10))
print("\n" + "="*50 + "\n") # Pemisah

# Visualisasi distribusi genre
plt.figure(figsize=(14, 8)) # Ukuran figure disesuaikan agar label genre terbaca
sns.barplot(x='jumlah_film', y='genre', data=genre_df, hue='genre', palette='viridis', dodge=False, legend=False)
plt.title('Distribusi Genre Film dalam Dataset', fontsize=15, pad=10)
plt.xlabel('Jumlah Film', fontsize=12)
plt.ylabel('Genre', fontsize=12)
plt.tight_layout() # Menyesuaikan layout agar label tidak terpotong
plt.show()

# Menampilkan genre yang '(no genres listed)' jika ada
if '(no genres listed)' in hitung_genre:
    print(f"\nPerhatian: Terdapat {hitung_genre['(no genres listed)']} film dengan '(no genres listed)'.")
    # Anda mungkin ingin melihat film-film ini:
    # print(movies_df[movies_df['genres'] == '(no genres listed)'])
else:
    print("\nTidak ada film dengan '(no genres listed)' dalam dataset.")

"""### Observasi Distribusi Genre Film:

Analisis frekuensi kemunculan setiap genre dalam dataset film menghasilkan temuan berikut:

* **Genre Paling Umum:**
    * Genre yang paling banyak muncul dalam dataset adalah **"Drama"** dengan total **4361** film.
    * Beberapa genre lain yang juga sangat umum (masuk 5 besar) adalah **"Comedy" (3756 film), "Thriller" (1894 film), "Action" (1828 film), dan "Romance" (1596 film)**.

* **Distribusi Genre (Bar Plot):**
    * Visualisasi bar plot menunjukkan variasi yang signifikan dalam jumlah film per genre.
    * Genre seperti **"Drama"** dan **"Comedy"** sangat mendominasi dataset.
    * Sebaliknya, genre seperti **"Film-Noir", "IMAX", dan "Western"** (terlihat di bagian bawah plot) memiliki representasi yang jauh lebih sedikit.

* **Film Tanpa Genre:**
    * Terdapat **34** film yang terdaftar tanpa informasi genre (`(no genres listed)`).
    * Keberadaan film tanpa genre ini perlu diperhatikan karena dapat mempengaruhi kinerja model Content-Based Filtering jika tidak ditangani dengan baik (misalnya, dengan menghapusnya, mengabaikannya, atau mencoba memberikan genre default jika memungkinkan).

Pemahaman distribusi genre ini krusial untuk pengembangan sistem rekomendasi berbasis konten, karena model akan belajar preferensi pengguna terhadap genre-genre ini. Genre yang sangat dominan mungkin lebih sering muncul dalam rekomendasi secara alami, sementara perhatian khusus mungkin diperlukan untuk memastikan film dari genre yang kurang umum juga memiliki kesempatan untuk direkomendasikan jika relevan dengan preferensi pengguna.

## **6. Pemeriksaan Missing Values**
"""

# Pemeriksaan missing values pada movies_df
print("Missing values di movies_df:\n")
print(movies_df.isnull().sum())
print("\n" + "="*50 + "\n")

# Pemeriksaan missing values pada ratings_df
print("Missing values di ratings_df:\n")
print(ratings_df.isnull().sum())
print("\n" + "="*50 + "\n")

# Jika Anda juga memuat tags_df, periksa juga:
# print("Missing values di tags_df:\n")
# print(tags_df.isnull().sum())
# print("\n" + "="*50 + "\n")

"""### Observasi Missing Values:

Berdasarkan pemeriksaan formal menggunakan `.isnull().sum()`:

* **Pada `movies_df`:**
    * Kolom `movieId`: Terdapat **0** missing values.
    * Kolom `title`: Terdapat **0** missing values.
    * Kolom `genres`: Terdapat **0** missing values.

* **Pada `ratings_df`:**
    * Kolom `userId`: Terdapat **0** missing values.
    * Kolom `movieId`: Terdapat **0** missing values.
    * Kolom `rating`: Terdapat **0** missing values.
    * Kolom `timestamp`: Terdapat **0** missing values.

Secara keseluruhan, dataset `movies_df` dan `ratings_df` yang digunakan untuk analisis ini **tidak memiliki missing values** pada kolom-kolom utamanya. Ini menunjukkan bahwa data cukup bersih dan siap untuk tahap Data Preparation tanpa perlu melakukan imputasi nilai yang hilang untuk kolom-kolom ini. Pengecualian adalah kolom `genres` pada `movies_df` yang memiliki beberapa entri `(no genres listed)` (sebanyak 34 film, seperti yang diidentifikasi sebelumnya), yang akan dipertimbangkan penanganannya pada tahap Data Preparation.

## **7. Penggabungan Data (Data Merging)**
"""

# Menggabungkan ratings_df dengan movies_df untuk mendapatkan judul dan genre film di samping rating
# Ini berguna untuk analisis dan juga bisa menjadi dasar untuk beberapa jenis model
merged_df = pd.merge(ratings_df, movies_df, on='movieId', how='left')

# Menampilkan beberapa baris pertama dari data yang digabungkan
# print("\nContoh Data Gabungan (merged_df):\n")
# print(merged_df.head())

"""### Catatan Mengenai Penggabungan Data:

Penggabungan (`merging`) beberapa DataFrame adalah langkah umum dan penting dalam analisis data dan persiapan data untuk machine learning. Dalam konteks dataset MovieLens ini:

* Menggabungkan `ratings_df` dengan `movies_df` (berdasarkan `movieId`) memungkinkan kita untuk secara langsung menganalisis rating pengguna bersamaan dengan informasi detail film seperti judul dan genre. DataFrame `merged_df` yang telah dibuat adalah contoh hasil dari operasi ini.
* DataFrame hasil gabungan ini bisa berguna untuk:
    * **Eksplorasi Data Lebih Lanjut:** Misalnya, melihat genre apa yang paling sering dirating tinggi oleh pengguna tertentu atau menganalisis rata-rata rating per genre.
    * **Feature Engineering:** Membuat fitur baru berdasarkan kombinasi data pengguna dan data film.
    * **Input untuk Model:** Beberapa implementasi model rekomendasi mungkin memerlukan tabel gabungan sebagai input.

Pada tahap Data Preparation dan Modeling nanti, kita mungkin akan sering melakukan operasi penggabungan ini atau menggunakan data yang sudah digabungkan seperti `merged_df`.

# **Tahap 4: Data Preparation**

## **1. Menangani Film dengan Genre (no genres listed)**
"""

# Menampilkan film dengan genre '(no genres listed)' sebelum dihapus
print("Jumlah film sebelum menghapus '(no genres listed)':", len(movies_df))
film_tanpa_genre = movies_df[movies_df['genres'] == '(no genres listed)']
print(f"Ditemukan {len(film_tanpa_genre)} film dengan genre '(no genres listed)'.")
# print("Contoh film tanpa genre:")
# print(film_tanpa_genre.head())

# 1. Mengidentifikasi movieId dari film yang tidak memiliki genre
movieIds_to_remove = film_tanpa_genre['movieId'].tolist()

# 2. Menghapus film-film tersebut dari movies_df
movies_df_cleaned = movies_df[~movies_df['movieId'].isin(movieIds_to_remove)].copy()
print(f"\nJumlah film setelah menghapus '(no genres listed)': {len(movies_df_cleaned)}")

# 3. Menghapus rating yang terkait dengan film-film tersebut dari ratings_df
ratings_df_cleaned = ratings_df[~ratings_df['movieId'].isin(movieIds_to_remove)].copy()
print(f"Jumlah rating sebelum menghapus film tanpa genre: {len(ratings_df)}")
print(f"Jumlah rating setelah menghapus film tanpa genre: {len(ratings_df_cleaned)}")

# Verifikasi bahwa film tanpa genre sudah tidak ada
print(f"\nJumlah film dengan genre '(no genres listed)' setelah pembersihan: {len(movies_df_cleaned[movies_df_cleaned['genres'] == '(no genres listed)'])}")

# Kita akan menggunakan movies_df_cleaned dan ratings_df_cleaned untuk langkah selanjutnya
# Ganti DataFrame lama dengan yang sudah dibersihkan jika Anda mau, atau gunakan nama baru ini.
# Untuk konsistensi, mari kita update DataFrame utama kita:
movies_df = movies_df_cleaned
ratings_df = ratings_df_cleaned

"""### 1. Menangani Film dengan Genre `(no genres listed)`

**Proses yang Dilakukan:**
Pada tahap Data Understanding, teridentifikasi sebanyak **34 film** yang memiliki atribut genre `(no genres listed)`. Karena fitur genre sangat penting untuk pendekatan Content-Based Filtering, keberadaan entri ini dianggap sebagai noise atau data yang tidak informatif untuk tujuan tersebut.

Langkah-langkah penanganan yang dilakukan adalah sebagai berikut:
1.  **Identifikasi `movieId`**: Semua `movieId` yang berasosiasi dengan film bergenre `(no genres listed)` dikumpulkan.
2.  **Penghapusan dari `movies_df`**: Baris-baris film yang memiliki `movieId` tersebut dihapus dari DataFrame `movies_df`. Jumlah film berkurang dari **9742** menjadi **9708**.
3.  **Penghapusan dari `ratings_df`**: Untuk menjaga konsistensi data, semua entri rating yang terkait dengan `movieId` yang telah dihapus juga dihilangkan dari DataFrame `ratings_df`. Jumlah rating berkurang dari **100836** menjadi **100789**.

**Alasan Diperlukannya Tahapan Ini:**
* **Kualitas Fitur untuk Content-Based Filtering:** Model Content-Based Filtering akan mengandalkan kemiripan antar film berdasarkan genrenya. Film tanpa informasi genre yang valid akan sulit diproses atau bahkan dapat menghasilkan rekomendasi yang tidak relevan.
* **Konsistensi Data:** Menghapus film dari `movies_df` tanpa menghapus rating terkaitnya di `ratings_df` akan menyebabkan adanya rating untuk film yang tidak lagi ada dalam daftar film kita, yang bisa menimbulkan error atau kebingungan di tahap selanjutnya.
* **Menyederhanakan Pemrosesan:** Dengan menghilangkan entri ini, proses *feature engineering* untuk genre menjadi lebih lugas.

Setelah tahapan ini, `movies_df` dan `ratings_df` yang telah dibersihkan (dan sudah diperbarui ke nama variabel semula) siap untuk proses persiapan data selanjutnya. Verifikasi akhir menunjukkan **0 film** dengan genre `(no genres listed)` tersisa.

## **2. Persiapan Data untuk Content-Based Filtering: Ekstraksi Fitur Genre**
"""

# Membuat salinan movies_df untuk menyimpan fitur genre
movies_with_genres_df = movies_df.copy()

# Melakukan One-Hot Encoding pada kolom 'genres' yang dipisahkan oleh '|'
# Setiap genre akan menjadi kolom baru dengan nilai 0 atau 1
genre_features = movies_with_genres_df['genres'].str.get_dummies(sep='|')

# Menampilkan beberapa baris pertama dari fitur genre yang dihasilkan
print("Contoh Fitur Genre Setelah One-Hot Encoding (Top 5 baris):\n")
print(genre_features.head())
print("\n" + "="*50 + "\n")

# Menampilkan dimensi dari fitur genre
print(f"Dimensi dari DataFrame fitur genre: {genre_features.shape}")
print(f"Ini berarti ada {genre_features.shape[1]} genre unik yang menjadi fitur.")
print("\n" + "="*50 + "\n")

# Menggabungkan fitur genre ini kembali ke DataFrame movies_with_genres_df
movies_with_genres_df = pd.concat([movies_with_genres_df, genre_features], axis=1)

# Menampilkan beberapa baris pertama dari DataFrame yang sudah digabungkan
# (termasuk kolom genre asli dan kolom-kolom genre baru)
print("Contoh movies_df setelah digabungkan dengan fitur genre (Top 5 baris):\n")
print(movies_with_genres_df.head())

"""### 2. Persiapan Data untuk Content-Based Filtering: Ekstraksi Fitur Genre

**Proses yang Dilakukan:**
Untuk memungkinkan model Content-Based Filtering memahami karakteristik film berdasarkan genrenya, kolom `genres` yang awalnya berupa string (misalnya, "Adventure|Animation|Children|Comedy|Fantasy") perlu diubah menjadi representasi numerik. Teknik yang digunakan adalah **One-Hot Encoding** (secara spesifik, menggunakan `str.get_dummies()` dari Pandas yang cocok untuk data multi-label yang dipisahkan oleh delimiter).

Langkah-langkahnya adalah sebagai berikut:
1.  Kolom `genres` dari `movies_df` (yang sudah dibersihkan dari film tanpa genre) diproses. Setiap string genre dipecah berdasarkan delimiter `|`.
2.  Sebuah DataFrame baru (`genre_features`) dibuat, di mana setiap **genre unik** menjadi sebuah **kolom baru**.
3.  Untuk setiap film, nilai pada kolom genre tersebut akan menjadi **1** jika film tersebut memiliki genre tersebut, dan **0** jika tidak. Output `genre_features.head()` menunjukkan contoh representasi biner ini.
4.  DataFrame `genre_features` ini kemudian digabungkan kembali dengan DataFrame `movies_df` (yang disalin sebagai `movies_with_genres_df`).

Hasilnya adalah DataFrame film yang kini memiliki sekumpulan kolom biner, masing-masing merepresentasikan keberadaan suatu genre. Berdasarkan output `genre_features.shape`, terdapat **19** kolom genre baru yang terbentuk, yang berarti ada 19 genre unik yang diidentifikasi dari dataset (setelah penghapusan film `(no genres listed)`). DataFrame `movies_with_genres_df` akhir memiliki 22 kolom (3 kolom asli + 19 kolom genre baru).

**Alasan Diperlukannya Tahapan Ini:**
* **Input Model Machine Learning:** Algoritma machine learning umumnya memerlukan input berupa data numerik. Representasi string genre tidak dapat langsung digunakan.
* **Kuantifikasi Fitur:** One-Hot Encoding mengubah fitur kategorikal (genre) menjadi format numerik yang dapat diukur dan dibandingkan oleh model.
* **Dasar Perhitungan Kemiripan:** Dalam Content-Based Filtering, kemiripan antar film akan dihitung berdasarkan fitur-fitur ini. Misalnya, dua film yang memiliki banyak angka '1' pada kolom genre yang sama akan dianggap lebih mirip.

DataFrame `movies_with_genres_df` yang berisi fitur-fitur genre numerik ini akan menjadi dasar untuk membangun profil item dalam model Content-Based Filtering.

## **3. Persiapan Data untuk Collaborative Filtering: Pembagian Data (Train-Test Split)**
"""

from sklearn.model_selection import train_test_split

# Data yang akan kita split adalah ratings_df
# Kita ingin memprediksi 'rating', jadi 'rating' bisa dianggap sebagai target,
# meskipun dalam CF, seluruh interaksi adalah data kita.
# X biasanya adalah fitur, y adalah target. Di sini, kita bisa menganggap
# seluruh baris rating sebagai data yang akan dibagi.

# Mengambil semua data rating sebagai dasar untuk splitting
X = ratings_df.copy() # Atau bisa juga ratings_df[['userId', 'movieId']]
y = ratings_df['rating'] # Targetnya adalah rating itu sendiri untuk stratifikasi jika diperlukan

# Melakukan pembagian data dengan rasio 80% train dan 20% test
# stratify=y bisa membantu jika distribusi rating sangat tidak seimbang,
# namun untuk CF, seringkali kita split seluruh interaksi.
# Untuk kasus CF yang umum, kita membagi interaksi (baris dari ratings_df)
# Mari kita split berdasarkan seluruh DataFrame ratings_df
train_ratings_df, test_ratings_df = train_test_split(
    ratings_df,
    test_size=0.2,       # 20% dari data akan menjadi test set
    random_state=42      # Seed untuk reproduktifitas hasil split
)

# Menampilkan ukuran dari masing-masing set
print("Ukuran Data Asli (ratings_df):", ratings_df.shape)
print("Ukuran Set Pelatihan (train_ratings_df):", train_ratings_df.shape)
print("Ukuran Set Pengujian (test_ratings_df):", test_ratings_df.shape)
print("\n" + "="*50 + "\n")

# Menampilkan beberapa contoh data dari set pelatihan dan pengujian
print("Contoh Data Pelatihan (Top 5 baris):\n")
print(train_ratings_df.head())
print("\n" + "="*50 + "\n")

print("Contoh Data Pengujian (Top 5 baris):\n")
print(test_ratings_df.head())

"""### 3. Persiapan Data untuk Collaborative Filtering: Pembagian Data (Train-Test Split)

**Proses yang Dilakukan:**
Untuk mengevaluasi kinerja model Collaborative Filtering secara objektif, dataset rating (`ratings_df`) dibagi menjadi dua bagian terpisah: set pelatihan (training set) dan set pengujian (test set). Pembagian ini dilakukan menggunakan fungsi `train_test_split` dari `scikit-learn`.

* Dataset `ratings_df` yang berisi **100789** interaksi rating dibagi.
* Sebesar **80%** dari data dialokasikan sebagai **set pelatihan (`train_ratings_df`)**, yang menghasilkan **80631** data.
* Sisa **20%** dialokasikan sebagai **set pengujian (`test_ratings_df`)**, yang menghasilkan **20158** data.
* Parameter `random_state` digunakan untuk memastikan pembagian data bersifat konsisten dan dapat direproduksi setiap kali kode dijalankan. Contoh data dari kedua set juga telah ditampilkan untuk verifikasi.

**Alasan Diperlukannya Tahapan Ini:**
* **Evaluasi Model yang Tidak Bias:** Model dilatih menggunakan set pelatihan. Kemudian, kinerjanya diuji pada set pengujian, yang berisi data yang belum pernah "dilihat" oleh model selama proses pelatihan. Ini memberikan estimasi yang lebih realistis tentang seberapa baik model akan berkinerja pada data baru di masa depan.
* **Mencegah Overfitting:** Jika model dievaluasi pada data yang sama dengan yang digunakan untuk melatihnya, model mungkin menunjukkan kinerja yang sangat baik karena ia "menghafal" data pelatihan, bukan belajar pola umum. Fenomena ini disebut overfitting. Penggunaan set pengujian terpisah membantu mendeteksi overfitting.
* **Dasar Perbandingan Model:** Metrik evaluasi yang dihitung pada set pengujian memungkinkan perbandingan yang adil antara berbagai model atau konfigurasi model Collaborative Filtering.

Set pelatihan (`train_ratings_df`) akan digunakan untuk melatih algoritma Collaborative Filtering, sementara `test_ratings_df` akan digunakan untuk mengukur seberapa akurat prediksi rating atau rekomendasi yang dihasilkan oleh model tersebut.

# **Tahap 5: Modeling and Result!**

## **A. Content-Based Filtering (CBF)**
"""

from sklearn.metrics.pairwise import cosine_similarity

# Kita akan menggunakan fitur genre yang sudah di One-Hot Encode.
# Pastikan movies_with_genres_df adalah DataFrame yang memiliki kolom movieId, title, genres (asli),
# dan kolom-kolom genre hasil one-hot encoding.

# Mengambil hanya bagian fitur genre (kolom-kolom hasil one-hot encoding)
# Kolom pertama setelah 'genres' adalah awal dari fitur genre one-hot encoded
# (movieId, title, genres) adalah 3 kolom pertama di movies_with_genres_df jika kita merujuk ke movies_df awal + OHE
# Jika movies_with_genres_df dibentuk dari movies_df.copy() lalu concat dengan genre_features,
# maka kita perlu memastikan kita hanya mengambil kolom OHE genre.

# Mari kita ambil fitur genre dari DataFrame yang sudah kita buat sebelumnya (genre_features)
# atau kita bisa membuatnya lagi dari movies_df (yang sudah dibersihkan dari (no genres listed))
# Untuk kepastian, mari kita pastikan kita memiliki DataFrame yang benar.
# movies_df saat ini adalah yang sudah bersih.

# Membuat ulang fitur genre dari movies_df yang sudah bersih, untuk kepastian
genre_matrix = movies_df['genres'].str.get_dummies(sep='|')
print(f"Dimensi matriks genre: {genre_matrix.shape}")
print("Contoh matriks genre (Top 5 baris):\n")
print(genre_matrix.head())
print("\n" + "="*50 + "\n")

# Menghitung cosine similarity antar film berdasarkan matriks genre
# Hasilnya adalah matriks (jumlah_film x jumlah_film)
cosine_sim_matrix = cosine_similarity(genre_matrix)

# Mengubah matriks similarity menjadi DataFrame agar lebih mudah dibaca (opsional, tapi berguna untuk inspeksi)
# Index dan kolomnya akan menjadi movieId (atau index film jika kita tidak set movieId sebagai index)
# Untuk kemudahan, kita gunakan index numerik dari movies_df
cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=movies_df['title'], columns=movies_df['title'])

print(f"Dimensi matriks cosine similarity: {cosine_sim_df.shape}")
print("Contoh matriks cosine similarity (Top 5x5 film):\n")
# Menampilkan sebagian kecil dari matriks similarity
print(cosine_sim_df.iloc[:5, :5])

"""### A.1. Content-Based Filtering: Perhitungan Kemiripan Film

**Proses yang Dilakukan:**
Langkah pertama dalam membangun sistem rekomendasi berbasis konten adalah mengukur seberapa mirip item (film) satu sama lain berdasarkan fiturnya. Dalam kasus ini, fitur utama yang digunakan adalah genre film.

1.  **Persiapan Matriks Fitur Genre:** Dari DataFrame `movies_df` (yang telah dibersihkan), kolom `genres` diubah menjadi representasi numerik menggunakan teknik One-Hot Encoding (via `str.get_dummies()`). Hasilnya adalah `genre_matrix`, di mana setiap baris merepresentasikan satu film dan setiap kolom merepresentasikan satu genre unik. Nilai dalam matriks ini adalah biner (0 atau 1), menunjukkan ada atau tidaknya suatu genre pada film tersebut. Matriks ini memiliki dimensi **9708 x 19** (9708 film dan 19 genre unik). Contoh dari matriks ini telah ditampilkan.

2.  **Perhitungan Cosine Similarity:** Metrik *Cosine Similarity* kemudian diterapkan pada `genre_matrix` untuk menghitung kemiripan antar semua pasangan film. Cosine similarity mengukur kosinus sudut antara dua vektor (dalam hal ini, vektor genre dari dua film).
    * Skor kemiripan berkisar dari 0 (tidak ada kesamaan genre) hingga 1 (genre yang dimiliki persis sama).
    * Hasilnya adalah sebuah matriks kemiripan (`cosine_sim_matrix` yang kemudian diubah menjadi `cosine_sim_df`) berukuran **9708 x 9708**. Setiap sel `(i, j)` dalam matriks ini berisi skor kemiripan antara film `i` dan film `j`. Diagonal utama matriks ini akan bernilai 1, karena setiap film identik dengan dirinya sendiri. Contoh 5x5 dari matriks ini menunjukkan skor kemiripan antar beberapa film.

**Alasan Diperlukannya Tahapan Ini:**
Matriks kemiripan ini adalah inti dari sistem rekomendasi berbasis konten. Dengan mengetahui seberapa mirip satu film dengan film lainnya berdasarkan konten (genre), kita dapat merekomendasikan film-film yang paling mirip dengan film yang pernah disukai atau sedang ditonton oleh pengguna.

## **A.2. Content-Based Filtering: Membuat Fungsi Rekomendasi**
"""

# Membuat Series Pandas dari judul film untuk memudahkan pencarian index berdasarkan judul
# movies_df sudah berisi 'movieId' dan 'title'
# cosine_sim_df sudah menggunakan judul film sebagai index dan kolom

def get_movie_recommendations_cbf(movie_title, similarity_df, movies_df, top_n=10):
    """
    Memberikan rekomendasi film berdasarkan kemiripan genre (Content-Based).

    Args:
        movie_title (str): Judul film yang menjadi referensi.
        similarity_df (pd.DataFrame): DataFrame matriks kemiripan antar film (judul x judul).
        movies_df (pd.DataFrame): DataFrame informasi film (harus punya kolom 'title').
        top_n (int): Jumlah rekomendasi yang diinginkan.

    Returns:
        pd.DataFrame: DataFrame berisi N film yang direkomendasikan beserta genrenya,
                      atau None jika film referensi tidak ditemukan.
    """
    if movie_title not in similarity_df.index:
        print(f"Film '{movie_title}' tidak ditemukan dalam dataset.")
        return None

    # 1. Mendapatkan skor kemiripan film referensi dengan semua film lain
    sim_scores = similarity_df[movie_title]

    # 2. Mengurutkan film berdasarkan skor kemiripan (descending)
    # dan mengubahnya menjadi list pasangan (judul_film, skor_kemiripan)
    sim_scores_sorted = sim_scores.sort_values(ascending=False)

    # 3. Mengambil Top-N film, mengabaikan film itu sendiri (yang pertama setelah diurutkan)
    # Karena film itu sendiri akan memiliki skor 1.0 dan berada di puncak.
    # Kita ambil top_n + 1, lalu buang yang pertama jika itu adalah film input.
    # Namun, jika ada film lain dengan skor 1.0 (genre sama persis), kita tetap ingin menampilkannya.
    # Cara yang lebih aman: ambil top_n+1, lalu filter film input jika ada.

    recommended_movie_titles = []
    for title, score in sim_scores_sorted.items():
        if title != movie_title: # Jangan merekomendasikan film itu sendiri
            recommended_movie_titles.append((title, score))
        if len(recommended_movie_titles) == top_n:
            break

    if not recommended_movie_titles:
        print(f"Tidak ada rekomendasi yang bisa diberikan untuk '{movie_title}'.")
        return None

    # Mengubah daftar rekomendasi menjadi DataFrame untuk tampilan yang lebih baik
    recommendations_df = pd.DataFrame(recommended_movie_titles, columns=['title', 'similarity_score'])

    # Menggabungkan dengan movies_df untuk mendapatkan genre dari film yang direkomendasikan
    recommendations_df = recommendations_df.merge(movies_df[['title', 'genres']], on='title', how='left')

    return recommendations_df

# --- Contoh Penggunaan Fungsi ---
# Pilih satu judul film dari dataset Anda untuk diuji
contoh_judul_film = 'Toy Story (1995)' # Pastikan judul ini ada di movies_df['title']

print(f"Rekomendasi untuk film '{contoh_judul_film}':\n")
rekomendasi_cbf = get_movie_recommendations_cbf(contoh_judul_film, cosine_sim_df, movies_df, top_n=10)

if rekomendasi_cbf is not None:
    print(rekomendasi_cbf)

print("\n" + "="*50 + "\n")

# Contoh lain, mungkin film dengan genre yang lebih spesifik
contoh_judul_film_2 = 'Matrix, The (1999)'
print(f"Rekomendasi untuk film '{contoh_judul_film_2}':\n")
rekomendasi_cbf_2 = get_movie_recommendations_cbf(contoh_judul_film_2, cosine_sim_df, movies_df, top_n=5)

if rekomendasi_cbf_2 is not None:
    print(rekomendasi_cbf_2)

"""### A.2. Content-Based Filtering: Fungsi Rekomendasi dan Hasilnya

**Cara Kerja Fungsi Rekomendasi:**  
Sebuah fungsi `get_movie_recommendations_cbf` telah dibuat untuk menghasilkan rekomendasi film berdasarkan kemiripan konten (genre). Fungsi ini bekerja dengan langkah-langkah berikut:
1. Menerima input berupa judul film referensi (`movie_title`), DataFrame matriks kemiripan (`cosine_sim_df`), DataFrame informasi film (`movies_df`), dan jumlah rekomendasi yang diinginkan (`top_n`).
2. Memeriksa ketersediaan film referensi dalam matriks kemiripan.
3. Mengambil vektor kemiripan film referensi terhadap semua film lain dari `cosine_sim_df`.
4. Mengurutkan film-film berdasarkan skor kemiripan tersebut secara menurun.
5. Memilih `top_n` film dengan skor kemiripan tertinggi, dengan mengabaikan film referensi itu sendiri dari daftar rekomendasi.
6. Menyajikan hasil rekomendasi dalam bentuk DataFrame yang berisi judul film, skor kemiripan, dan genre film yang direkomendasikan.

**Contoh Hasil Top-N Recommendation:**

**Untuk Film Referensi: `Toy Story (1995)`**  
Genre asli `Toy Story (1995)`: `Adventure|Animation|Children|Comedy|Fantasy`  
Berikut adalah 10 film yang direkomendasikan:

| title                                                   | similarity_score | genres                                            |
|----------------------------------------------------------|------------------|---------------------------------------------------|
| Antz (1998)                                              | 1.0              | Adventure\|Animation\|Children\|Comedy\|Fantasy   |
| Emperor's New Groove, The (2000)                         | 1.0              | Adventure\|Animation\|Children\|Comedy\|Fantasy   |
| Moana (2016)                                             | 1.0              | Adventure\|Animation\|Children\|Comedy\|Fantasy   |
| Asterix and the Vikings (Astérix et les Vikings, 2006)   | 1.0              | Adventure\|Animation\|Children\|Comedy\|Fantasy   |
| The Good Dinosaur (2015)                                 | 1.0              | Adventure\|Animation\|Children\|Comedy\|Fantasy   |
| Toy Story 2 (1999)                                       | 1.0              | Adventure\|Animation\|Children\|Comedy\|Fantasy   |
| Wild, The (2006)                                         | 1.0              | Adventure\|Animation\|Children\|Comedy\|Fantasy   |
| Monsters, Inc. (2001)                                    | 1.0              | Adventure\|Animation\|Children\|Comedy\|Fantasy   |
| Turbo (2013)                                             | 1.0              | Adventure\|Animation\|Children\|Comedy\|Fantasy   |
| Adventures of Rocky and Bullwinkle, The (2000)           | 1.0              | Adventure\|Animation\|Children\|Comedy\|Fantasy   |

*Observasi Singkat:*  
Film-film yang direkomendasikan untuk `Toy Story (1995)` semuanya memiliki skor kemiripan 1.0. Ini berarti mereka memiliki kombinasi genre yang **persis sama** (`Adventure|Animation|Children|Comedy|Fantasy`) dengan film referensi. Sistem ini efektif menemukan film-film dengan profil genre identik.

**Untuk Film Referensi: `Matrix, The (1999)`**  
Genre asli `Matrix, The (1999)`: `Action|Sci-Fi|Thriller`  
Berikut adalah 5 film yang direkomendasikan:

| title             | similarity_score | genres                  |
|-------------------|------------------|--------------------------|
| Predators (2010)  | 1.0              | Action\|Sci-Fi\|Thriller |
| Screamers (1995)  | 1.0              | Action\|Sci-Fi\|Thriller |
| Firefox (1982)    | 1.0              | Action\|Sci-Fi\|Thriller |
| Equilibrium (2002)| 1.0              | Action\|Sci-Fi\|Thriller |
| Death Race 2 (2010)| 1.0             | Action\|Sci-Fi\|Thriller |

*Observasi Singkat:*  
Rekomendasi untuk `Matrix, The (1999)` juga menunjukkan film-film dengan skor kemiripan 1.0, yang berarti semuanya memiliki genre `Action|Sci-Fi|Thriller`, sama persis dengan film referensi. Ini konsisten dengan pendekatan berbasis konten yang sangat bergantung pada kesamaan fitur yang didefinisikan.

## **A.3. Content-Based Filtering: Kelebihan dan Kekurangan**

### A.3. Content-Based Filtering: Kelebihan dan Kekurangan

Pendekatan Content-Based Filtering (CBF) yang telah kita implementasikan memiliki beberapa karakteristik, kelebihan, dan kekurangan yang perlu dipahami:

**Kelebihan Content-Based Filtering:**

1.  **Independensi Pengguna (User Independence):**
    * Rekomendasi untuk seorang pengguna tidak dipengaruhi oleh preferensi pengguna lain. Setiap pengguna mendapatkan rekomendasi yang disesuaikan murni berdasarkan profil dan preferensi itemnya sendiri.

2.  **Transparansi dan Interpretasi (Transparency & Interpretability):**
    * Hasil rekomendasi CBF cenderung lebih mudah dijelaskan. Misalnya, "Kami merekomendasikan film X karena Anda menyukai film Y, dan keduanya bergenre Action dan Sci-Fi." Ini bisa meningkatkan kepercayaan pengguna.

3.  **Tidak Ada Masalah "Cold Start" untuk Item Baru (No New Item Cold Start):**
    * Selama item baru memiliki deskripsi fitur yang memadai (misalnya, genre, sutradara, aktor), item tersebut dapat langsung direkomendasikan kepada pengguna yang profilnya cocok, bahkan jika item tersebut belum pernah mendapatkan interaksi (rating) dari pengguna manapun.

4.  **Mampu Merekomendasikan Item Niche/Kurang Populer:**
    * CBF dapat merekomendasikan item yang tidak populer secara umum asalkan fiturnya sesuai dengan preferensi pengguna. Ini berbeda dengan beberapa metode Collaborative Filtering yang cenderung bias ke item populer.

**Kekurangan Content-Based Filtering:**

1.  **Ketergantungan pada Kualitas Analisis Konten/Fitur (Feature Representation Dependency):**
    * Kualitas rekomendasi sangat bergantung pada seberapa baik fitur item diekstraksi dan direpresentasikan. Jika fitur yang digunakan terbatas (misalnya, hanya genre seperti dalam implementasi kita) atau kurang deskriptif, rekomendasi mungkin menjadi kurang akurat atau relevan. Proses *feature engineering* bisa menjadi kompleks dan membutuhkan pengetahuan domain.

2.  **Overspecialisasi dan Kurangnya Serendipity (Lack of Novelty/Serendipity):**
    * CBF cenderung merekomendasikan item yang sangat mirip dengan apa yang sudah disukai pengguna di masa lalu. Ini dapat membatasi pengguna untuk menemukan item baru yang menarik dari kategori atau jenis yang berbeda, mengurangi elemen kejutan atau *serendipity*. Misalnya, jika pengguna hanya menyukai film komedi, sistem akan terus merekomendasikan film komedi.

3.  **Masalah "Cold Start" untuk Pengguna Baru (New User Cold Start):**
    * CBF memerlukan data preferensi awal dari pengguna (misalnya, item yang pernah disukai atau dirating) untuk membangun profil pengguna. Untuk pengguna baru yang belum memiliki riwayat interaksi, sistem akan kesulitan memberikan rekomendasi yang personal dan akurat.

4.  **Kesulitan Menangkap Nuansa atau Kualitas Subjektif:**
    * CBF mungkin kesulitan membedakan antara item berkualitas baik dan buruk jika keduanya memiliki fitur yang sama. Kualitas artistik, alur cerita yang mendalam, atau aspek subjektif lainnya seringkali sulit untuk direpresentasikan sebagai fitur eksplisit.

Dalam implementasi kita yang berfokus pada genre, kita melihat bahwa sistem mampu menemukan film dengan genre yang identik atau sangat mirip. Namun, ini juga menunjukkan potensi overspecialisasi jika hanya genre yang dipertimbangkan.

## **B. Collaborative Filtering (CF)**
"""

!pip install numpy==1.26.4

!pip install scikit-surprise

from surprise import Reader, Dataset, SVD
from surprise.model_selection import train_test_split as surprise_train_test_split # Mengganti nama agar tidak bentrok
from surprise import accuracy # Untuk evaluasi nanti

# 1. Mendefinisikan Reader
# Reader digunakan untuk parsing file atau DataFrame.
# Kita perlu menentukan skala rating kita. Dari EDA, kita tahu ratingnya 0.5 - 5.0.
reader = Reader(rating_scale=(0.5, 5.0))

# 2. Memuat data dari DataFrame Pandas ke format Dataset Surprise
# Kita akan menggunakan train_ratings_df dan test_ratings_df yang sudah kita buat.
# Surprise memerlukan kolom dalam urutan tertentu: user, item, rating.
# Kolom 'timestamp' bersifat opsional.
data_train_surprise = Dataset.load_from_df(train_ratings_df[['userId', 'movieId', 'rating']], reader)
# data_test_surprise = Dataset.load_from_df(test_ratings_df[['userId', 'movieId', 'rating']], reader) # Ini tidak kita gunakan langsung untuk build testset di cara ini

# 3. Membangun trainset dan testset versi Surprise
# Dari keseluruhan data_train_surprise, kita akan membuat trainset yang bisa digunakan untuk melatih model.
trainset_surprise = data_train_surprise.build_full_trainset()

# Membuat testset dari data testing yang sudah kita pisahkan sebelumnya
# Testset di Surprise adalah list of tuples (uid, iid, r_ui_true)
testset_surprise = [(uid, iid, r_ui_true) for uid, iid, r_ui_true in test_ratings_df[['userId', 'movieId', 'rating']].itertuples(index=False)]


print("Data berhasil dimuat ke format Surprise.")
print(f"Jumlah pengguna di trainset_surprise: {trainset_surprise.n_users}")
print(f"Jumlah item di trainset_surprise: {trainset_surprise.n_items}")
print(f"Jumlah rating di trainset_surprise: {trainset_surprise.n_ratings}")
print(f"Jumlah rating di testset_surprise (untuk evaluasi): {len(testset_surprise)}")

"""### B.1. Collaborative Filtering: Persiapan Data untuk Library `Surprise`

**Proses yang Dilakukan:**
Untuk memanfaatkan algoritma Collaborative Filtering dari library `Surprise`, data rating perlu dikonversi ke dalam format spesifik yang dapat dipahami oleh library tersebut. Langkah-langkah yang dilakukan adalah sebagai berikut:

1.  **Pendefinisian `Reader`**: Sebuah objek `Reader` dari `Surprise` dibuat untuk menentukan bagaimana data rating akan di-parse, termasuk mendefinisikan skala rating yang digunakan (dalam kasus ini, 0.5 hingga 5.0).
2.  **Memuat Data dari DataFrame**:
    * Data rating dari `train_ratings_df` (yang berisi kolom `userId`, `movieId`, `rating`) dimuat ke dalam objek `Dataset` `Surprise` menggunakan `Dataset.load_from_df()`. Ini menghasilkan `data_train_surprise`.
3.  **Pembuatan `trainset`**: Objek `trainset_surprise` dibangun dari `data_train_surprise` menggunakan metode `build_full_trainset()`. Objek `trainset` ini adalah struktur data utama yang digunakan oleh algoritma `Surprise` untuk proses pelatihan model. Output menunjukkan bahwa `trainset_surprise` berisi **610** pengguna, **8956** item, dan **80631** rating.
4.  **Pembuatan `testset`**: Objek `testset_surprise` dibuat dari `test_ratings_df` dengan mengubahnya menjadi list of tuples dengan format `(userId, movieId, actual_rating)`. Ini akan digunakan untuk evaluasi prediksi rating. Terdapat **20158** rating dalam `testset_surprise`.

**Alasan Diperlukannya Tahapan Ini:**
Library `Surprise` memiliki struktur data internal sendiri untuk mengoptimalkan perhitungan dan implementasi berbagai algoritma rekomendasi. Dengan mengubah data kita ke format `Reader`, `Dataset`, `trainset`, dan `testset` `Surprise`, kita memastikan kompatibilitas dan dapat menggunakan fungsionalitas penuh dari library tersebut, termasuk pelatihan model, prediksi, dan evaluasi.

## **B.2. Collaborative Filtering: Melatih Model SVD**
"""

# Mengimpor SVD jika belum diimpor sebelumnya
from surprise import SVD

# 1. Inisialisasi model SVD
# Kita bisa menggunakan parameter default terlebih dahulu.
# Beberapa parameter penting:
# n_factors: Jumlah faktor laten (default 100)
# n_epochs: Jumlah iterasi (epoch) saat training (default 20)
# lr_all: Learning rate untuk semua parameter (default 0.005)
# reg_all: Term regulariasi untuk semua parameter (default 0.02)
svd_model = SVD(n_factors=100, n_epochs=25, lr_all=0.007, reg_all=0.05, random_state=42)

# 2. Melatih model menggunakan trainset_surprise
print("Memulai pelatihan model SVD...")
svd_model.fit(trainset_surprise)
print("Pelatihan model SVD selesai.")

# Model svd_model sekarang sudah terlatih dan siap digunakan untuk prediksi.

"""### B.2. Collaborative Filtering: Pelatihan Model SVD

**Proses yang Dilakukan:**
Setelah data disiapkan dalam format yang sesuai untuk library `Surprise`, langkah selanjutnya adalah melatih model Collaborative Filtering. Untuk proyek ini, algoritma yang dipilih adalah SVD (Singular Value Decomposition), salah satu teknik faktorisasi matriks yang populer.

1.  **Inisialisasi Model SVD**: Sebuah instance dari model `SVD` dibuat. Beberapa parameter yang dapat diatur saat inisialisasi antara lain:
    * `n_factors`: Jumlah faktor laten yang akan dipelajari (misalnya, 100).
    * `n_epochs`: Jumlah epoch atau iterasi pelatihan (misalnya, 25).
    * `lr_all`: Tingkat pembelajaran (learning rate).
    * `reg_all`: Parameter regularisasi untuk mencegah overfitting.
    * `random_state`: Untuk memastikan hasil inisialisasi yang konsisten.
    Parameter-parameter ini dapat di-tuning untuk mendapatkan performa model yang lebih baik, namun untuk tahap awal, nilai default atau nilai yang umum digunakan bisa diterapkan.

2.  **Pelatihan Model**: Model SVD yang telah diinisialisasi kemudian dilatih menggunakan `trainset_surprise` (data pelatihan yang sudah disiapkan). Selama proses pelatihan, model SVD akan mencoba mempelajari representasi faktor laten untuk setiap pengguna dan item sedemikian rupa sehingga ketika faktor-faktor ini dikalikan, hasilnya mendekati rating aktual yang ada di data pelatihan. Ini biasanya dilakukan melalui proses optimasi seperti *Stochastic Gradient Descent (SGD)*.

Setelah proses `fit()` selesai, `svd_model` kini berisi model yang telah terlatih dan siap digunakan untuk membuat prediksi rating untuk pasangan pengguna-item yang belum ada di data pelatihan, atau untuk menghasilkan top-N rekomendasi.

**Alasan Diperlukannya Tahapan Ini:**
Pelatihan model adalah inti dari pendekatan berbasis model dalam machine learning. Dengan melatih model SVD pada data historis rating, kita memungkinkan model untuk "belajar" pola preferensi implisit dan karakteristik pengguna serta item. Model yang terlatih ini kemudian dapat menggeneralisasi pengetahuannya untuk memprediksi interaksi di masa depan atau interaksi yang tidak diketahui.

## **B.3. Collaborative Filtering: Membuat Fungsi Rekomendasi SVD dan Hasilnya**
"""

import pandas as pd

def get_movie_recommendations_cf_svd(user_id, svd_model, movies_df, trainset, top_n=10):
    """
    Memberikan rekomendasi film untuk pengguna tertentu menggunakan model SVD terlatih.

    Args:
        user_id (int): ID pengguna yang ingin diberi rekomendasi.
        svd_model (surprise.prediction_algorithms.matrix_factorization.SVD): Model SVD yang sudah terlatih.
        movies_df (pd.DataFrame): DataFrame informasi film (harus punya kolom 'movieId', 'title', 'genres').
        trainset (surprise.trainset.Trainset): Trainset yang digunakan untuk melatih model (untuk mengetahui item yang sudah dirating).
        top_n (int): Jumlah rekomendasi yang diinginkan.

    Returns:
        pd.DataFrame: DataFrame berisi N film yang direkomendasikan beserta judul, genre, dan prediksi rating,
                      atau None jika user_id tidak valid atau tidak ada rekomendasi.
    """
    try:
        # Mendapatkan inner id pengguna dari trainset (Surprise menggunakan inner id)
        user_inner_id = trainset.to_inner_uid(user_id)
    except ValueError:
        print(f"User ID {user_id} tidak ditemukan dalam trainset.")
        return None

    # 1. Dapatkan daftar movieId yang sudah dirating oleh pengguna
    rated_movie_inner_ids = [item_inner_id for (item_inner_id, _) in trainset.ur[user_inner_id]]
    rated_movie_ids = [trainset.to_raw_iid(inner_id) for inner_id in rated_movie_inner_ids]

    # 2. Dapatkan semua movieId unik dari movies_df
    all_movie_ids = movies_df['movieId'].unique()

    # 3. Dapatkan movieId yang belum dirating oleh pengguna
    unrated_movie_ids = [movie_id for movie_id in all_movie_ids if movie_id not in rated_movie_ids]

    if not unrated_movie_ids:
        print(f"Pengguna {user_id} sudah merating semua film yang ada, atau tidak ada film baru untuk direkomendasikan.")
        return None

    # 4. Prediksi rating untuk film yang belum dirating
    predictions = []
    for movie_id in unrated_movie_ids:
        # model.predict() mengembalikan objek Prediction
        # Kita butuh nilai estimasi (est)
        pred = svd_model.predict(uid=user_id, iid=movie_id)
        predictions.append({'movieId': movie_id, 'predicted_rating': pred.est})

    # 5. Urutkan prediksi berdasarkan predicted_rating tertinggi
    predictions_df = pd.DataFrame(predictions)
    top_recommendations = predictions_df.sort_values(by='predicted_rating', ascending=False).head(top_n)

    # 6. Gabungkan dengan informasi film (judul, genre)
    top_recommendations = top_recommendations.merge(movies_df[['movieId', 'title', 'genres']], on='movieId', how='left')

    return top_recommendations[['title', 'genres', 'predicted_rating']]

# --- Contoh Penggunaan Fungsi ---
# Pilih satu user_id dari dataset Anda untuk diuji
# Pastikan user_id ini ada di train_ratings_df['userId']
# Anda bisa cek misalnya: train_ratings_df['userId'].unique()
contoh_user_id = 1 # Ganti dengan user_id yang valid dari data Anda

print(f"Rekomendasi SVD untuk User ID {contoh_user_id} (Top 10):\n")
rekomendasi_svd = get_movie_recommendations_cf_svd(contoh_user_id, svd_model, movies_df, trainset_surprise, top_n=10)

if rekomendasi_svd is not None:
    print(rekomendasi_svd)
else:
    print(f"Tidak dapat menghasilkan rekomendasi untuk User ID {contoh_user_id}.")

print("\n" + "="*50 + "\n")

# Contoh lain
contoh_user_id_2 = 100 # Ganti dengan user_id yang valid lainnya
print(f"Rekomendasi SVD untuk User ID {contoh_user_id_2} (Top 5):\n")
rekomendasi_svd_2 = get_movie_recommendations_cf_svd(contoh_user_id_2, svd_model, movies_df, trainset_surprise, top_n=5)

if rekomendasi_svd_2 is not None:
    print(rekomendasi_svd_2)
else:
    print(f"Tidak dapat menghasilkan rekomendasi untuk User ID {contoh_user_id_2}.")

"""### B.3. Collaborative Filtering: Fungsi Rekomendasi SVD dan Hasilnya

**Cara Kerja Fungsi Rekomendasi SVD:**  
Sebuah fungsi `get_movie_recommendations_cf_svd` dikembangkan untuk menghasilkan top-N rekomendasi film bagi pengguna tertentu, berdasarkan model SVD yang telah dilatih. Langkah-langkah utama fungsi ini adalah:
1. Menerima input `user_id`, model SVD terlatih (`svd_model`), DataFrame informasi film (`movies_df`), `trainset` dari `Surprise` (untuk mengetahui film yang sudah dirating), dan jumlah rekomendasi (`top_n`).
2. Mengidentifikasi semua `movieId` yang **belum pernah** dirating oleh `user_id` tersebut. Ini dilakukan dengan membandingkan daftar semua film yang ada dengan daftar film yang sudah dirating oleh pengguna (diambil dari `trainset`).
3. Untuk setiap film yang belum dirating, model SVD (`svd_model.predict()`) digunakan untuk menghasilkan **prediksi rating**.
4. Semua prediksi rating untuk film yang belum dirating tersebut dikumpulkan.
5. Prediksi diurutkan dari yang memiliki estimasi rating tertinggi ke terendah.
6. `top_n` film teratas diambil sebagai rekomendasi.
7. Informasi tambahan seperti judul dan genre film kemudian digabungkan ke dalam hasil rekomendasi untuk tampilan yang lebih informatif.

---

**Contoh Hasil Top-N Recommendation:**

#### Untuk User ID: `1`  
Berikut adalah 10 film yang direkomendasikan beserta prediksi ratingnya:

| title                                                   | genres                                           | predicted_rating |
|----------------------------------------------------------|--------------------------------------------------|------------------|
| Lawrence of Arabia (1962)                                | Adventure\|Drama\|War                            | 5.0              |
| Godfather: Part II, The (1974)                           | Crime\|Drama                                     | 5.0              |
| Touch of Evil (1958)                                     | Crime\|Film-Noir\|Thriller                       | 5.0              |
| Gladiator (1992)                                         | Action\|Drama                                    | 5.0              |
| Three Billboards Outside Ebbing, Missouri (2017)         | Crime\|Drama                                     | 5.0              |
| Yojimbo (1961)                                           | Action\|Adventure                                | 5.0              |
| Great Escape, The (1963)                                 | Action\|Adventure\|Drama\|War                    | 5.0              |
| Glory (1989)                                             | Drama\|War                                       | 5.0              |
| Grand Day Out with Wallace and Gromit, A (1989)          | Adventure\|Animation\|Children\|Comedy\|Sci-Fi   | 5.0              |
| Godfather, The (1972)                                    | Crime\|Drama                                     | 5.0              |

*Observasi Singkat:*  
Rekomendasi untuk User ID `1` menunjukkan film-film dengan prediksi rating tertinggi, yaitu 5.0 untuk semua 10 film teratas. Ini mengindikasikan bahwa model SVD sangat percaya diri bahwa pengguna ini akan sangat menyukai film-film klasik dan yang mendapat pujian tinggi dari berbagai genre seperti Drama, War, Crime, dan Adventure.

---

#### Untuk User ID: `100`  
Berikut adalah 5 film yang direkomendasikan beserta prediksi ratingnya:

| title                                                   | genres                                           | predicted_rating |
|----------------------------------------------------------|--------------------------------------------------|------------------|
| Yojimbo (1961)                                           | Action\|Adventure                                | 4.685115         |
| Cookie's Fortune (1999)                                  | Comedy\|Drama                                    | 4.678235         |
| Cool Hand Luke (1967)                                    | Drama                                            | 4.614846         |
| Three Billboards Outside Ebbing, Missouri (2017)         | Crime\|Drama                                     | 4.612072         |
| Grand Day Out with Wallace and Gromit, A (1989)          | Adventure\|Animation\|Children\|Comedy\|Sci-Fi   | 4.593617         |

*Observasi Singkat:*  
Untuk User ID `100`, model SVD merekomendasikan film-film dengan prediksi rating yang juga sangat tinggi, berkisar antara 4.59 hingga 4.68. Rekomendasi ini juga mencakup berbagai genre, menunjukkan kemampuan SVD untuk menangkap preferensi yang mungkin lebih beragam atau nuansa yang tidak hanya berdasarkan genre eksplisit seperti pada Content-Based Filtering.

## **B.4. Collaborative Filtering (SVD): Kelebihan dan Kekurangan**

### B.4. Collaborative Filtering (SVD): Kelebihan dan Kekurangan

Pendekatan Collaborative Filtering (CF), khususnya yang menggunakan teknik faktorisasi matriks seperti SVD, memiliki serangkaian kelebihan dan kekurangan yang membedakannya dari Content-Based Filtering:

**Kelebihan Collaborative Filtering (SVD):**

1.  **Tidak Memerlukan Analisis Konten Item (No Domain Knowledge Required for Item Features):**
    * CF bekerja berdasarkan data interaksi pengguna-item (misalnya, rating) saja. Tidak perlu melakukan ekstraksi fitur manual atau analisis mendalam terhadap konten item (seperti genre, deskripsi, dll.). Ini sangat berguna jika metadata item sulit didapatkan atau kompleks untuk diolah.

2.  **Mampu Menemukan Rekomendasi yang Mengejutkan (Serendipity & Novelty):**
    * Karena CF mempelajari pola dari perilaku kolektif pengguna, ia dapat menemukan item yang menarik bagi pengguna meskipun item tersebut tidak memiliki kemiripan fitur yang jelas dengan apa yang pernah disukai pengguna sebelumnya. Ini memungkinkan penemuan item yang lebih beragam dan tidak terduga (serendipity).

3.  **Mempelajari Pola Preferensi yang Kompleks (Learns Complex Patterns):**
    * Teknik faktorisasi matriks seperti SVD dapat menangkap hubungan dan pola preferensi yang halus dan kompleks (faktor laten) dalam data yang mungkin tidak terlihat oleh manusia atau oleh model berbasis fitur eksplisit.

4.  **Performa yang Cenderung Baik pada Data Padat (Good Performance on Denser Data):**
    * Jika data interaksi cukup banyak, model CF (terutama model-based) seringkali dapat menghasilkan rekomendasi yang sangat akurat.

5.  **Relatif Baik dalam Menangani Sparsitas (Model-Based CF like SVD):**
    * Meskipun data rating seringkali sparse (banyak pasangan user-item yang tidak memiliki rating), teknik faktorisasi matriks seperti SVD dirancang untuk dapat menggeneralisasi dari rating yang ada dan memprediksi rating untuk entri yang kosong, sehingga lebih tahan terhadap sparsitas dibandingkan metode memory-based CF murni.

**Kekurangan Collaborative Filtering (SVD):**

1.  **Masalah "Cold Start" (New User and New Item Cold Start):**
    * **Pengguna Baru:** Sulit memberikan rekomendasi yang akurat kepada pengguna baru yang belum memiliki (atau hanya memiliki sedikit) riwayat interaksi/rating, karena tidak ada data perilaku masa lalu untuk dipelajari.
    * **Item Baru:** Item baru yang belum pernah mendapatkan rating dari pengguna manapun juga sulit untuk direkomendasikan, karena item tersebut belum masuk ke dalam matriks interaksi yang digunakan untuk melatih model.

2.  **Bias Popularitas (Popularity Bias):**
    * Algoritma CF seringkali cenderung merekomendasikan item-item yang sudah populer. Hal ini karena item populer memiliki lebih banyak data interaksi, sehingga lebih mudah bagi model untuk "mempelajarinya" dan menganggapnya relevan bagi banyak pengguna. Ini bisa membuat item yang kurang populer (niche) lebih sulit untuk muncul dalam rekomendasi.

3.  **Ketergantungan pada Jumlah Data Interaksi (Data Sparsity Challenge):**
    * Meskipun SVD bisa menangani sparsitas sampai batas tertentu, jika data interaksi pengguna-item sangat sedikit atau sangat sparse, kualitas rekomendasi akan menurun karena model tidak memiliki cukup informasi untuk mempelajari pola preferensi secara efektif.

4.  **Kurang Transparan/Sulit Diinterpretasikan (Less Transparency/Interpretability):**
    * Rekomendasi yang dihasilkan oleh model berbasis faktorisasi matriks seperti SVD seringkali lebih sulit untuk dijelaskan kepada pengguna ("black box"). Menjelaskan mengapa suatu item direkomendasikan berdasarkan "kecocokan faktor laten" kurang intuitif dibandingkan penjelasan berbasis fitur ("Anda menyukai genre ini").

5.  **Skalabilitas untuk Pelatihan (Scalability for Training):**
    * Meskipun SVD lebih scalable dibandingkan beberapa metode CF memory-based, melatih model faktorisasi matriks pada dataset yang sangat besar (jutaan pengguna dan item) masih bisa membutuhkan sumber daya komputasi yang signifikan dan waktu yang lama.

Dalam implementasi kita, model SVD memberikan rekomendasi berdasarkan pola rating historis, yang bisa jadi berbeda dan melengkapi rekomendasi dari Content-Based Filtering.

# **Tahap 6: Evaluation!**
"""

from surprise import accuracy

# Membuat prediksi pada testset_surprise menggunakan model SVD yang sudah terlatih
predictions_svd = svd_model.test(testset_surprise)

# Menghitung RMSE
rmse_svd = accuracy.rmse(predictions_svd, verbose=True)

# Menghitung MAE
mae_svd = accuracy.mae(predictions_svd, verbose=True)

print(f"\nNilai RMSE untuk model SVD: {rmse_svd}")
print(f"Nilai MAE untuk model SVD: {mae_svd}")

"""### Evaluasi Kinerja Model SVD

**Metrik yang Digunakan:**

Untuk mengevaluasi akurasi prediksi rating dari model **SVD**, metrik yang digunakan adalah:

1. **Root Mean Squared Error (RMSE)**  
   Mengukur akar kuadrat dari rata-rata selisih kuadrat antara rating aktual dan prediksi. Memberikan penalti lebih besar untuk error yang lebih besar.

   $$
   RMSE = \sqrt{\frac{1}{N} \sum_{(u,i) \in \text{TestSet}} (r_{ui} - \hat{r}_{ui})^2}
   $$

2. **Mean Absolute Error (MAE)**  
   Mengukur rata-rata dari selisih absolut antara rating aktual dan prediksi.

   $$
   MAE = \frac{1}{N} \sum_{(u,i) \in \text{TestSet}} \left| r_{ui} - \hat{r}_{ui} \right|
   $$


**Proses Perhitungan:**
1.  Model SVD yang telah dilatih digunakan untuk membuat prediksi rating pada `testset_surprise`. Test set ini berisi pasangan pengguna-item beserta rating aktualnya yang tidak dilihat model selama pelatihan.
2.  Fungsi `accuracy.rmse()` dan `accuracy.mae()` dari library `Surprise` kemudian menghitung nilai error berdasarkan perbandingan antara rating aktual dan rating hasil prediksi model pada test set tersebut.

**Hasil dan Interpretasi:**
* Nilai **RMSE** yang diperoleh adalah: **0.8628**
* Nilai **MAE** yang diperoleh adalah: **0.6618**

Interpretasi hasil ini:
* Secara rata-rata, prediksi rating yang diberikan oleh model SVD memiliki kesalahan absolut sebesar **0.6618** poin rating dari rating aktual. Mengingat skala rating kita adalah 0.5 hingga 5.0, ini menunjukkan bahwa rata-rata prediksi model meleset sekitar setengah hingga satu poin rating.
* RMSE yang bernilai **0.8628** sedikit lebih tinggi dari MAE, yang mengindikasikan adanya beberapa prediksi dengan error yang lebih besar (karena RMSE lebih sensitif terhadap error besar). Namun, secara umum, kedua nilai ini menunjukkan bahwa model SVD memberikan performa yang cukup baik dalam memprediksi rating pengguna pada dataset MovieLens Small ini.
* Nilai ini memberikan gambaran kuantitatif tentang seberapa dekat prediksi model dengan preferensi aktual pengguna. Untuk sistem rekomendasi, nilai RMSE di bawah 1.0 seringkali dianggap sebagai hasil yang cukup baik, terutama sebagai baseline awal.

## **2. Evaluasi untuk Content-Based Filtering (CBF)**

### Evaluasi Model Content-Based Filtering (CBF)

Evaluasi untuk model Content-Based Filtering (CBF) yang dibangun dalam proyek ini mencakup aspek **kualitatif** dan **kuantitatif**. Output utama model adalah daftar film yang mirip berdasarkan fitur konten (genre).

#### **a. Evaluasi Kualitatif**

**Pendekatan Evaluasi yang Digunakan:**
1.  **Observasi Relevansi Hasil Rekomendasi:** Setelah fungsi rekomendasi CBF dibuat, beberapa film sampel (misalnya, 'Toy Story (1995)' dan 'Matrix, The (1999)') digunakan sebagai input untuk menghasilkan daftar Top-N rekomendasi.
2.  **Analisis Kesamaan Fitur (Genre):** Genre dari film-film yang direkomendasikan kemudian dibandingkan dengan genre film input. Tujuan utamanya adalah untuk memverifikasi apakah model berhasil mengidentifikasi film-film dengan profil genre yang serupa atau identik.

**Hasil dan Interpretasi (Kualitatif):**
* Seperti yang ditunjukkan pada bagian "A.2. Content-Based Filtering: Fungsi Rekomendasi dan Hasilnya", untuk film input yang diberikan, model CBF secara konsisten merekomendasikan film-film yang memiliki **skor kemiripan genre 1.0**. Ini berarti semua film yang direkomendasikan memiliki **kombinasi genre yang persis sama** dengan film referensi.
* Contohnya, untuk 'Toy Story (1995)' yang bergenre `Adventure|Animation|Children|Comedy|Fantasy`, semua 10 film teratas yang direkomendasikan juga memiliki set genre yang identik. Hal serupa terjadi untuk 'Matrix, The (1999)' dengan genre `Action|Sci-Fi|Thriller`.
* Hasil ini mengonfirmasi bahwa implementasi Content-Based Filtering menggunakan One-Hot Encoding genre dan Cosine Similarity bekerja sesuai dengan yang diharapkan, yaitu mengidentifikasi item berdasarkan kesamaan maksimal pada fitur yang didefinisikan.

---

#### **b. Evaluasi Kuantitatif: Precision@K**

Meskipun CBF murni berbasis kemiripan item tidak secara langsung memprediksi rating, kita dapat mengevaluasi kemampuannya untuk merekomendasikan item yang relevan kepada pengguna dengan menggunakan metrik seperti Precision@K.

**Pendekatan untuk Precision@K:**
1.  Kita akan menggunakan `test_ratings_df` sebagai dasar untuk "ground truth".
2.  Untuk setiap pengguna dalam `test_ratings_df`, kita akan mengambil satu film yang mereka rating tinggi (misalnya, rating >= 4.0) sebagai *query item*.
3.  Kita akan meminta rekomendasi Top-K dari model CBF berdasarkan *query item* tersebut.
4.  Kemudian, kita akan memeriksa berapa banyak dari K rekomendasi tersebut yang juga merupakan film *lain* yang dirating tinggi oleh pengguna yang sama di `test_ratings_df`.
5.  Precision@K dihitung sebagai: (Jumlah item relevan yang direkomendasikan dalam Top-K) / K.
6.  Nilai Precision@K rata-rata di seluruh pengguna uji akan dilaporkan.

**Metrik yang Digunakan:**

- **Precision@K**  
  Mengukur proporsi item yang direkomendasikan dalam K item teratas yang benar-benar relevan bagi pengguna.

  $$
  \text{Precision@K} = \frac{\text{Jumlah item relevan dan direkomendasikan dalam Top-K}}{K}
  $$
"""

# ---------------------------------------------------------------------------
# EKSEKUSI PERHITUNGAN PRECISION@K (BAGIAN INI TETAP SAMA)
# ---------------------------------------------------------------------------
# Asumsikan movies_df, test_ratings_df, dan cosine_sim_df sudah ada dari sel sebelumnya
# movies_df adalah DataFrame film yang sudah dibersihkan
# cosine_sim_df adalah matriks kemiripan (judul x judul) dari movies_df bersih

print("Memulai perhitungan Precision@K untuk Content-Based Filtering...")

# Hitung Precision@10 untuk CBF
precision_cbf_at_10 = calculate_precision_at_k_cbf(
    test_ratings_df,
    movies_df,
    cosine_sim_df,
    k_val=10,
    rating_thresh=4.0
)

# Hitung Precision@5 untuk CBF
precision_cbf_at_5 = calculate_precision_at_k_cbf(
    test_ratings_df,
    movies_df,
    cosine_sim_df,
    k_val=5,
    rating_thresh=4.0
)

# ---------------------------------------------------------------------------
# MODIFIKASI TAMPILAN OUTPUT PRINT (BAGIAN INI YANG DIPERBAIKI)
# ---------------------------------------------------------------------------

print("\n===================================================================")
print("           HASIL EVALUASI CONTENT-BASED FILTERING (CBF)          ")
print("===================================================================")
print("Metrik: Precision@K")
print("-------------------------------------------------------------------")
print(f"  Precision@10: {precision_cbf_at_10:.4f}")
print(f"  Precision@5 : {precision_cbf_at_5:.4f}")
print("-------------------------------------------------------------------")
print("\nInterpretasi Singkat:")
if precision_cbf_at_10 < 0.1: # Anda bisa sesuaikan threshold ini
    print("  > Nilai Precision@K yang diperoleh untuk CBF berbasis genre murni")
    print("    cukup rendah. Ini mengindikasikan bahwa kemiripan genre saja")
    print("    memiliki keterbatasan dalam merekomendasikan item yang relevan")
    print("    secara konsisten menurut riwayat rating pengguna.")
    print("  > Untuk Precision@10, dari 10 film yang direkomendasikan, rata-rata")
    print(f"    kurang dari {precision_cbf_at_10*10:.2f} film yang relevan.")
else:
    print("  > Model CBF menunjukkan kemampuan untuk merekomendasikan item relevan.")
    print(f"  > Untuk Precision@10, dari 10 film yang direkomendasikan, rata-rata")
    print(f"    sekitar {precision_cbf_at_10*10:.2f} film yang relevan.")

print("\nCatatan:")
print("  - Evaluasi ini menggunakan satu query item per pengguna dari test set.")
print("  - Relevansi ditentukan berdasarkan rating >= 4.0 pada item lain di test set.")
print("===================================================================")